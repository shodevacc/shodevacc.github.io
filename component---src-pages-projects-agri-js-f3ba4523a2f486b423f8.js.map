{"version":3,"sources":["webpack://shoaib-alyaan-portfolio/./src/style/ThemeContext.js","webpack://shoaib-alyaan-portfolio/./src/components/Nav/HamburgerIcon.js","webpack://shoaib-alyaan-portfolio/./src/components/Nav/Nav1.js","webpack://shoaib-alyaan-portfolio/./src/components/Layout/Page.js","webpack://shoaib-alyaan-portfolio/./src/pages/projects/agri.js","webpack://shoaib-alyaan-portfolio/./src/style/projects/agri.module.css"],"names":["theme","colors","navBg","cinnabar","blue","dblue","lblue","menu","background","subtle","lgreen","green","shadow","title","card","zIndex","nav","navIcon","cursor","cursorOverLay","constant","navHeight","outerMargin","sizes","xs","sm","md","lg","fontSize","Global","createGlobalStyle","Icon","styled","Bar","dark","open","setOpen","BarRef","useRef","BarRef1","onClick","state","ref","Container","NavBar","showNavBarBg","NavItems","NavLink","CloseArea","useState","setShowNavBarBg","ContainerRef","CloseAreaRef","useEffect","handleScroll","window","scrollY","addEventListener","passive","removeEventListener","e","current","target","style","opacity","Link","to","PaddContainer","darkNav","children","addPadd","ThemeProvider","data","filteredData","agri","edges","forEach","edge","node","name","childImageSharp","gatsbyImageData","className","styles","margin","textAlign","rel","href","color","textDecoration","G","image","block","listStyleType","inception","transfer","proposed","maxWidth","verticalAlign","snippet","landing","Report","table","matrix","container","float","figName"],"mappings":"4LAEaA,EAAQ,CACnBC,OAAQ,CACNC,MAAO,UACPC,SAAS,UACTC,KAAM,UACNC,MAAO,UACPC,MAAO,UACPC,KAAM,UACNC,WAAY,OACZC,OAAQ,UACRC,OAAQ,UACRC,MAAO,WAETC,OAAQ,CACNC,MAAO,2CACPC,KAAM,wDAERC,OAAQ,CACNC,IAAK,GACLT,KAAM,GACNU,QAAS,GACTC,OAAQ,IACRC,cAAe,MAEjBC,SAAU,CACRC,UAAU,OACVC,YAAY,QAEdC,MAAO,CACLC,GAAI,6CACJC,GAAI,6CACJC,GAAI,6CACJC,GAAI,8CAENC,SAAU,CACRf,MAAO,SAIEgB,GAASC,uBAAH,m3H,oBCtCbC,EAAOC,yBAAH,+DAAGA,CAAH,wFAaJC,EAAMD,yBAAH,8DAAGA,CAAH,uOAGO,gBAAGhC,EAAH,EAAGA,MAAH,SAAUkC,KAAkBlC,EAAMC,OAAOE,SAAW,UAOnD,qBAAGgC,KACZ,oCAAyC,UAKlC,qBAAGA,KAAgB,IAAS,OAK1B,qBAAGA,KACZ,sCAA2C,UAenD,EAZsB,SAAC,GAAqC,IAAnCA,EAAkC,EAAlCA,KAAMC,EAA4B,EAA5BA,QAA4B,IAAnBF,YAAmB,SACnDG,GAASC,cACTC,GAAUD,cAEhB,OACE,gBAACP,EAAD,CAAMS,QAAS,kBAAMJ,GAAQ,SAAAK,GAAK,OAAKA,OACrC,gBAACR,EAAD,CAAKC,KAAMA,EAAMC,KAAMA,EAAMO,IAAKL,IAClC,gBAACJ,EAAD,CAAKC,KAAMA,EAAMC,KAAMA,EAAMO,IAAKH,IAClC,gBAACN,EAAD,CAAKC,KAAMA,EAAMC,KAAMA,MC3CvBQ,EAAYX,yBAAH,2DAAGA,CAAH,iIASE,qBAAGG,KAAe,iDAI7BS,EAASZ,yBAAH,wDAAGA,CAAH,sLAIE,qBAAGhC,MAAkBoB,SAASC,aAU1B,cAAGrB,MAAH,SAAU6C,aAAkC,kBAAoB,mBAG5EC,EAAWd,yBAAH,0DAAGA,CAAH,gFAGI,qBAAGhC,MAAkBC,OAAOC,SAG/B,qBAAGF,MAAkBoB,SAASC,aAEvC,qBAAGrB,MAAkBuB,MAAMG,MAI3BqB,EAAUf,yBAAH,yDAAGA,CAAH,+FASG,qBAAGhC,MAAkBC,OAAOE,YAGtC6C,EAAYhB,yBAAH,2DAAGA,CAAH,2CAgFf,MArEA,YAAiC,IAAD,IAAhBE,YAAgB,YACJe,eAAS,GAA1Bd,EADqB,KACfC,EADe,QAEYa,eAAS,GAA1CJ,EAFqB,KAEPK,EAFO,KAGtBC,GAAeb,cACfc,GAAed,cA6BrB,OAhBAe,gBAAU,WAEN,IAAMC,EAAe,YAEZT,GAAgBU,OAAOC,SAAW,GACnCN,GAAgB,GAEXL,GAAgBU,OAAOC,QAAU,IACtCN,GAAgB,IAIxB,OADAK,OAAOE,iBAAiB,SAAUH,EAAc,CAAEI,SAAS,IACpD,WACHH,OAAOI,oBAAoB,SAAUL,EAAc,CAAEI,SAAS,OAEnE,CAACb,IAEA,gCACI,gBAACF,EAAD,CAAWD,IAAKS,EAAchB,KAAMA,EAAMK,QA7B/B,SAACoB,GAGZzB,GAAQgB,EAAaU,SAAWD,EAAEE,SAElCV,EAAaS,QAAQE,MAAMC,QAAU,EACrC5B,GAAQ,MAwBJ,gBAACU,EAAD,CAAUX,KAAMA,GACZ,gBAACY,EAAD,KACI,yBACI,gBAAC,EAAAkB,KAAD,CAAMC,GAAG,KAAT,UAIR,gBAACnB,EAAD,KACI,yBACC,gBAAC,EAAAkB,KAAD,CAAMC,GAAG,gBAAT,iBAGL,gBAACnB,EAAD,KACI,6BAAI,gBAAC,EAAAkB,KAAD,CAAMC,GAAG,aAAT,uBAGR,gBAACnB,EAAD,KACI,yBAAG,gBAAC,EAAAkB,KAAD,CAAMC,GAAG,iBAAT,mBAIX,gBAAClB,EAAD,CAAWN,IAAKU,EAAcjB,KAAMA,EAAMK,QAAS,kBAAMJ,GAAQ,OAErE,gBAACQ,EAAD,CAAQC,aAAcA,GAClB,gBAAC,EAAD,CAAeX,KAAMA,EAAMC,KAAMA,EAAMC,QAASA,OC5H1D+B,EAAgBnC,yBAAH,8DAAGA,CAAH,+EAET,qBAAGhC,MAAkBoB,SAASC,aAEtC,qBAAGrB,MAAkBuB,MAAMG,MACf,qBAAG1B,MAAkBoB,SAASC,aAgB5C,MAbA,YAAoE,IAAD,IAAnD+C,eAAmD,SAApCC,EAAoC,EAApCA,SAAUxD,EAA0B,EAA1BA,MAA0B,IAAnByD,eAAmB,SAC/D,OACI,gBAAC,EAAAC,cAAD,CAAevE,MAAOA,GAClB,gBAAC6B,EAAD,MACA,gBAAC,IAAD,CAAKhB,MAAOA,GAAS,kBACrB,gBAAC,EAAD,CAAKqB,KAAMkC,IACVE,EAAU,gBAACH,EAAD,KACNE,GACcA,K,oFC2X/B,UA5YA,YAAyB,IAATG,EAAQ,EAARA,KACVC,EAAe,GAMnB,OAJAD,EAAKE,KAAKC,MAAMC,SAAQ,SAAAC,GACtBJ,EAAaI,EAAKC,KAAKC,MAAQF,EAAKC,KAAKE,gBAAgBC,mBAIzD,gBAAC,IAAD,CAAMb,SAAO,EAACE,SAAO,EAACzD,MAAM,qBAC1B,uBAAKqE,UAAWC,MACd,uCACA,sBAAIpB,MAAO,CAAEqB,OAAQ,eAAgBC,UAAW,WAAhD,kBACkB,IAChB,qBACEvB,OAAO,SACPwB,IAAI,sBACJC,KAAK,oCACLxB,MAAO,CAAEyB,MAAO,OAAQC,eAAgB,cAJ1C,WASF,uBAAKP,UAAWC,MACd,2BACE,gBAAC,EAAAO,EAAD,CAAaC,MAAOlB,EAAamB,QACjC,qBAAGV,UAAWC,MAAd,6BAEF,2BACE,2BACE,sBAAID,UAAU,cAAd,gBACA,kNAG2D,2BAH3D,gIAK8C,2BAL9C,sJAKuM,2BALvM,yDAQA,sBAAIA,UAAU,cAAd,aACA,0BACE,4IAGA,mIASR,sBAAIA,UAAU,cAAd,YACA,0BACE,gKAEE,0BACE,sQAQJ,mGAGA,0GAKF,sBAAIA,UAAU,cAAd,aACA,0BACE,sFAGA,kGAKF,sBAAIA,UAAU,cAAd,gBACA,iHAIA,0BACE,6GAIA,oJAIA,2LAOF,sBAAIA,UAAU,cAAd,gBACA,2WAOE,2BACA,2BARF,mFAYA,sBAAInB,MAAO,CAAE8B,cAAe,SAC1B,2GAIA,mJAKF,2BAtHF,4UA2HkD,IAChD,2BACE,gBAAC,EAAAH,EAAD,CAAaC,MAAOlB,EAAaqB,YACjC,qBAAGZ,UAAWC,MAAd,4BAEF,2HAIA,0BACE,0BACE,yBACE,+CADF,0PAKmB,KAEnB,0BACE,mEACA,4DACA,qHAMJ,0BACE,yBACE,8CADF,2WASF,0BACE,yBACE,2CADF,qlBAaF,0BACE,yBACE,mDADF,kMAOF,0BACE,yBACE,2CADF,2vBAiBJ,41BAeA,sBAAID,UAAU,cAAd,qBACA,2BACE,gBAAC,EAAAQ,EAAD,CAAaC,MAAOlB,EAAasB,WACjC,qBAAGb,UAAWC,MAAd,2BAEF,+KAIE,2BAJF,kJAQE,2BARF,4UAeA,qIAGE,2BAHF,gFAKE,2BALF,mNASE,2BATF,0NAaE,2BACA,2BAdF,8GAe8C,2BAC5C,2BAhBF,oTAuBA,sBAAID,UAAU,cAAd,kBACA,2BACE,gBAAC,EAAAQ,EAAD,CACEC,MAAOlB,EAAauB,SACpBjC,MAAO,CAAEkC,SAAU,QAASb,OAAQ,UACtC,qBAAGF,UAAWC,MAAd,wBAEF,yBACE,oCADF,sDAEE,2BACA,oCAHF,+BAIE,2BACA,oCALF,sCAME,2BACA,oCAPF,qIASe,2BACb,oCAVF,mBAUgC,2BAC9B,oCAXF,mQAeE,2BACA,2BACA,gCAEE,wBAAMpB,MAAO,CAAEmC,cAAe,QAAStE,SAAU,SAAjD,MAAqE,IAFvE,UAIK,IArBP,mEAsBkE,2BAChE,gCAEE,wBAAMmC,MAAO,CAAEmC,cAAe,QAAStE,SAAU,SAAjD,MAAqE,IAFvE,UAIK,IA3BP,oHA8BE,2BACA,2BACA,qBAAGmC,MAAO,CAAEnC,SAAU,SAAtB,YAhCF,aAgCyD,IACvD,8CAjCF,mNAoCuB,mDApCvB,kOAwCK,IACH,kJAzCF,gEA6CgE,IAC9D,yCA9CF,0BAgDA,2BACE,gBAAC,EAAA8D,EAAD,CACEC,MAAOlB,EAAa0B,QACpBpC,MAAO,CAAEkC,SAAU,QAASb,OAAQ,UACtC,qBAAGF,UAAWC,MAAd,4BAEF,sBAAID,UAAU,cAAd,WACA,4KAIE,2BAJF,iIAQA,2BACE,gBAAC,EAAAQ,EAAD,CAAaC,MAAOlB,EAAa2B,UACjC,qBAAGlB,UAAWC,MAAd,2CAIF,qNAKA,2BACE,gBAAC,EAAAO,EAAD,CAAaC,MAAOlB,EAAa4B,OAAQtC,MAAO,CAAEkC,SAAU,QAASb,OAAQ,UAC7E,qBAAGF,UAAWC,MAAd,qCAEF,yBACG,IADH,4aAUA,uBAAKD,UAAWC,MACd,2BACE,gBAAC,EAAAO,EAAD,CAAaC,MAAOlB,EAAa6B,QACjC,qBAAGpB,UAAWC,MAAd,kEAKF,2BACE,gBAAC,EAAAO,EAAD,CAAaC,MAAOlB,EAAa8B,SACjC,qBAAGrB,UAAWC,MAAd,iE,mHCzXL,MAAMqB,EAAY,gCACZC,EAAQ,4BACRC,EAAU","file":"component---src-pages-projects-agri-js-f3ba4523a2f486b423f8.js","sourcesContent":["import { createGlobalStyle } from \"styled-components\"\n\nexport const theme = {\n  colors: {\n    navBg: '#1f4954',\n    cinnabar:'#e94f37',\n    blue: \"#0b0c22\",\n    dblue: \"#08091b\",\n    lblue: \"#1da2e7\",\n    menu: \"#105d86\",\n    background: \"#fff\",\n    subtle: \"#cccccc\",\n    lgreen: \"#dcffba\",\n    green: \"#5a7f4f\",\n  },\n  shadow: {\n    title: \"0 0em 0.2em #38ade9, 0 0em 0.2em #0d6f58\",\n    card: \"0 0 3em 0.4em #1ca2e7b8, inset 0 0 1em 0em #1ca2e7b8\",\n  },\n  zIndex: {\n    nav: 10,\n    menu: 11,\n    navIcon: 12,\n    cursor: 1000,\n    cursorOverLay: 1001,\n  },\n  constant: {\n    navHeight: `8rem`,\n    outerMargin: `4rem`,\n  },\n  sizes: {\n    xs: \"@media only screen and (min-width: 400px) \",\n    sm: \"@media only screen and (min-width: 568px) \",\n    md: \"@media only screen and (min-width: 768px) \",\n    lg: \"@media only screen and (min-width: 992px) \",\n  },\n  fontSize: {\n    title: \"24px\",\n  },\n}\n\nexport const Global = createGlobalStyle`\nhtml {\n  -ms-text-size-adjust: 100%;\n  -webkit-text-size-adjust: 100%;\n  box-sizing: border-box;\n  overflow-y: scroll;\n  font: georgia, serif, sans-serif;\n  font-size: 62.5% !important;\n}\nbody {\n  background: var(--ivory);\n  margin: 0;\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n  color: hsla(0, 0%, 0%, 0.8);\n  font-family: georgia, serif;\n  font-weight: normal;\n  word-wrap: break-word;\n  font-kerning: normal;\n  -moz-font-feature-settings: \"kern\", \"liga\", \"clig\", \"calt\";\n  -ms-font-feature-settings: \"kern\", \"liga\", \"clig\", \"calt\";\n  -webkit-font-feature-settings: \"kern\", \"liga\", \"clig\", \"calt\";\n  font-feature-settings: \"kern\", \"liga\", \"clig\", \"calt\";\n}\n* {\n  box-sizing: inherit;\n}\n*:before {\n  box-sizing: inherit;\n}\n*:after {\n  box-sizing: inherit;\n}\n\nhtml {\n  -ms-text-size-adjust: 100%;\n  -webkit-text-size-adjust: 100%;\n  box-sizing: border-box;\n  overflow-y: scroll;\n  font: georgia, serif, sans-serif;\n  font-size: 62.5% !important;\n}\nbody {\n  background: var(--ivory);\n  margin: 0;\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n  color: hsla(0, 0%, 0%, 0.8);\n  font-family: georgia, serif;\n  font-weight: normal;\n  word-wrap: break-word;\n  font-kerning: normal;\n  -moz-font-feature-settings: \"kern\", \"liga\", \"clig\", \"calt\";\n  -ms-font-feature-settings: \"kern\", \"liga\", \"clig\", \"calt\";\n  -webkit-font-feature-settings: \"kern\", \"liga\", \"clig\", \"calt\";\n  font-feature-settings: \"kern\", \"liga\", \"clig\", \"calt\";\n}\n* {\n  box-sizing: inherit;\n}\n*:before {\n  box-sizing: inherit;\n}\n*:after {\n  box-sizing: inherit;\n}\nh2 {\n  font-size: 2.56rem;\n  margin-left: 0;\n  margin-right: 0;\n  margin-top: 0;\n  padding-bottom: 0;\n  padding-left: 0;\n  padding-right: 0;\n  padding-top: 0;\n  margin-bottom: 1.45rem;\n  color: inherit;\n  font-family: \"Poppins\",-apple-system, BlinkMacSystemFont, Segoe UI, Roboto, Oxygen,\n    Ubuntu, Cantarell, Fira Sans, Droid Sans, Helvetica Neue, sans-serif;\n  font-weight: bold;\n  text-rendering: optimizeLegibility;\n  font-size: 1.62671rem;\n  line-height: 1.1;\n}\nh3 {\n  font-size: 2.2rem;\n  margin-left: 0;\n  margin-right: 0;\n  margin-top: 0;\n  padding-bottom: 0;\n  padding-left: 0;\n  padding-right: 0;\n  padding-top: 0;\n  margin-bottom: 1.45rem;\n  color: inherit;\n  font-family: \"Poppins\",-apple-system, BlinkMacSystemFont, Segoe UI, Roboto, Oxygen,\n    Ubuntu, Cantarell, Fira Sans, Droid Sans, Helvetica Neue, sans-serif;\n  font-weight: bold;\n  text-rendering: optimizeLegibility;\n  /* font-size: 1.38316rem; */\n  line-height: 1.1;\n}\nh4 {\n  font-size: 1.8rem;\n  margin-left: 0;\n  margin-right: 0;\n  margin-top: 0;\n  padding-bottom: 0;\n  padding-left: 0;\n  padding-right: 0;\n  padding-top: 0;\n  margin-bottom: 1.45rem;\n  color: inherit;\n  font-family: \"Poppins\",-apple-system, BlinkMacSystemFont, Segoe UI, Roboto, Oxygen,\n    Ubuntu, Cantarell, Fira Sans, Droid Sans, Helvetica Neue, sans-serif;\n  font-weight: bold;\n  text-rendering: optimizeLegibility;\n  /* font-size: 1rem; */\n  line-height: 1.1;\n}\nh5 {\n  margin-left: 0;\n  margin-right: 0;\n  margin-top: 0;\n  padding-bottom: 0;\n  padding-left: 0;\n  padding-right: 0;\n  padding-top: 0;\n  margin-bottom: 1.45rem;\n  color: inherit;\n  font-family: \"Poppins\",-apple-system, BlinkMacSystemFont, Segoe UI, Roboto, Oxygen,\n    Ubuntu, Cantarell, Fira Sans, Droid Sans, Helvetica Neue, sans-serif;\n  font-weight: bold;\n  text-rendering: optimizeLegibility;\n  font-size: 0.85028rem;\n  line-height: 1.1;\n}\nh6 {\n  margin-left: 0;\n  margin-right: 0;\n  margin-top: 0;\n  padding-bottom: 0;\n  padding-left: 0;\n  padding-right: 0;\n  padding-top: 0;\n  margin-bottom: 1.45rem;\n  color: inherit;\n  font-family: \"Poppins\",-apple-system, BlinkMacSystemFont, Segoe UI, Roboto, Oxygen,\n    Ubuntu, Cantarell, Fira Sans, Droid Sans, Helvetica Neue, sans-serif;\n  font-weight: bold;\n  text-rendering: optimizeLegibility;\n  font-size: 0.78405rem;\n  line-height: 1.1;\n}\n\na {\n  background-color: transparent;\n  -webkit-text-decoration-skip: objects;\n  text-decoration: none;\n  color: #000;\n}\np {\n  font-size: 16px;\n  margin-left: 0;\n  margin-right: 0;\n  margin-top: 0;\n  padding-bottom: 0;\n  padding-left: 0;\n  padding-right: 0;\n  padding-top: 0;\n  margin-bottom: 1.45rem;\n  font-family: \"Poppins\",-apple-system, BlinkMacSystemFont, Segoe UI, Roboto, Oxygen,\n    Ubuntu, Cantarell, Fira Sans, Droid Sans, Helvetica Neue, sans-serif;\n}\nul {\n  margin-left: 1.45rem;\n  margin-right: 0;\n  margin-top: 0;\n  padding-bottom: 0;\n  padding-left: 0;\n  padding-right: 0;\n  padding-top: 0;\n  margin-bottom: 1.45rem;\n  list-style-position: outside;\n  list-style-image: none;\n}\n\nblockquote {\n  margin-left: 1.45rem;\n  margin-right: 1.45rem;\n  margin-top: 0;\n  padding-bottom: 0;\n  padding-left: 0;\n  padding-right: 0;\n  padding-top: 0;\n  margin-bottom: 1.45rem;\n}\n`\n","import React, { useEffect, useRef } from \"react\"\nimport styled from \"styled-components\"\n\nconst Icon = styled.div`\n  position: relative;\n\n  cursor: pointer;\n\n  font-size: 15px;\n  height: 1em;\n  width: 2em;\n\n  z-index: 1000;\n  /* transform: translate(0, -49%); */\n\n`\nconst Bar = styled.div`\n  height: 0.2em;\n  width: 100%;\n  background: ${({ theme, dark }) => dark ? theme.colors.cinnabar : '#fff'};\n  border-radius:15px;\n  position: absolute;\n  transition: 0.3s ease;\n  :first-child {\n    top: 0px;\n    left: 0;\n    transform: ${({ open }) =>\n    open ? `translate(0, 0.5em) rotate(45deg)` : \"none\"};\n  }\n  :nth-child(2) {\n    top: 50%;\n    left: 0;\n    opacity: ${({ open }) => (open ? `0` : \"1\")};\n  }\n  :last-child {\n    top: 100%;\n    left: 0;\n    transform: ${({ open }) =>\n    open ? `translate(0, -0.5em) rotate(-45deg)` : \"none\"};\n  }\n`\nconst HamburgerIcon = ({ open, setOpen, dark = false }) => {\n  const BarRef = useRef()\n  const BarRef1 = useRef()\n\n  return (\n    <Icon onClick={() => setOpen(state => !state)}>\n      <Bar dark={dark} open={open} ref={BarRef} />\n      <Bar dark={dark} open={open} ref={BarRef1} />\n      <Bar dark={dark} open={open} />\n    </Icon>\n  )\n}\nexport default HamburgerIcon\n","import React, { useState, useRef, useEffect } from 'react'\nimport { Link } from 'gatsby'\nimport styled from 'styled-components'\nimport HamburgerIcon from './HamburgerIcon'\n\n\nconst Container = styled.div`\n    /* background: ${({ open }) => open ? 'rgba(0,0,0,0.4)' : 'transparent'}; */\n    width:100vw;\n    height:100vh;\n    position: fixed;\n    top:0;\n    left:0;\n    z-index:1000;\n    display: flex;\n    transform: ${({ open }) => open ? `translate3d(0,0,0)` : `translate3d(-101%,0,0)`};\n    transition: transform .3s ease;\n    /* pointer-events:${({ open }) => open ? \"auto\" : \"none\"}; */\n`\nconst NavBar = styled.div`\n    position: fixed;\n    top:0%;\n    left:0%;\n    height: ${({ theme }) => theme.constant.navHeight};\n    width: 100%;\n    display: flex;\n    justify-content: flex-start;\n    align-items: center;\n    padding: 0 6.5rem;\n    pointer-events: auto;\n\n    z-index:1001;\n\n    background: ${({ theme, showNavBarBg }) => showNavBarBg ? 'rgba(0,0,0,0.8)' : 'rgba(0,0,0,0)'};\n    /* backdrop-filter: blur(10px); */\n`\nconst NavItems = styled.div`\n    width:80vw;\n    height:100vh;\n    background: ${({ theme }) => theme.colors.navBg};\n   \n\n    padding: ${({ theme }) => theme.constant.navHeight} 0 0 5%;\n\n    ${({ theme }) => theme.sizes.md}{\n        width:50vw;\n    }\n`\nconst NavLink = styled.div`\n    margin: 1rem 0;\n    font-size:16px;\n    font-weight: 600;\n    color:#fff; \n    a{\n        color:#fff; \n    }\n    a:hover{\n        color:${({ theme }) => theme.colors.cinnabar};\n    }\n`\nconst CloseArea = styled.div`\nheight:100vh;\n/* width:20vw; */\n/* background: rgba(0,0,0,0.4); */\n /* opacity: ${({ open }) => open ? '1' : '0'}; */\n transition: opacity 0.2s;\n /* ${({ theme }) => theme.sizes.md}{\n        width:50vw;\n    } */\n`\n\nfunction Nav1({ dark = false }) {\n    const [open, setOpen] = useState(false)\n    const [showNavBarBg, setShowNavBarBg] = useState(false)\n    const ContainerRef = useRef()\n    const CloseAreaRef = useRef()\n\n    const CheckClick = (e) => {\n\n        // console.log(e.target, ContainerRef.current, ContainerRef.current == e.target)\n        if (open && ContainerRef.current == e.target) {\n            // console.log(\"CLILCKU\")\n            CloseAreaRef.current.style.opacity = 0;\n            setOpen(false);\n        }\n\n    }\n\n    useEffect(() => {\n\n        const handleScroll = () => {\n            // console.log(window.scrollY,showNavBarBg)\n            if (!showNavBarBg && window.scrollY >= 40) {\n                setShowNavBarBg(true)\n            }\n            else if (showNavBarBg && window.scrollY < 40) {\n                setShowNavBarBg(false)\n            }\n        }\n        window.addEventListener(\"scroll\", handleScroll, { passive: true })\n        return () => {\n            window.removeEventListener(\"scroll\", handleScroll, { passive: true })\n        }\n    }, [showNavBarBg])\n    return (\n        <>\n            <Container ref={ContainerRef} open={open} onClick={CheckClick}>\n                <NavItems open={open} >\n                    <NavLink>\n                        <p>\n                            <Link to=\"/\">Home</Link>\n                        </p>\n\n                    </NavLink>\n                    <NavLink>\n                        <p\n                        ><Link to=\"/internships\">Internships</Link></p>\n\n                    </NavLink>\n                    <NavLink>\n                        <p> <Link to=\"/projects\">Academic projects</Link></p>\n\n                    </NavLink>\n                    <NavLink>\n                        <p><Link to=\"/Publications\">Publications</Link></p>\n\n                    </NavLink>\n                </NavItems>\n                <CloseArea ref={CloseAreaRef} open={open} onClick={() => setOpen(false)} />\n            </Container>\n            <NavBar showNavBarBg={showNavBarBg}>\n                <HamburgerIcon dark={dark} open={open} setOpen={setOpen} />\n            </NavBar>\n\n        </>\n\n\n    )\n}\n\nexport default Nav1\n","import React from 'react'\nimport styled, { ThemeProvider } from \"styled-components\"\nimport { theme, Global } from \"../../style/ThemeContext\"\nimport SEO from '../seo'\nimport Nav from '../Nav/Nav1'\n\n//Container with added padding for appropriate nav height and side margins\nconst PaddContainer = styled.div`\nmax-width:100vw;\nmargin: ${({ theme }) => theme.constant.navHeight} 2rem 2rem 2rem;\n\n${({ theme }) => theme.sizes.md}{\n    margin: ${({ theme }) => theme.constant.navHeight} 3rem 3rem 3rem;\n}\n`\nfunction Page({ darkNav=false, children, title, addPadd = false }) {\n    return (\n        <ThemeProvider theme={theme}>\n            <Global />\n            <SEO title={title || \"Shoaib Alyaan\"} />\n            <Nav dark={darkNav} />\n            {addPadd ? <PaddContainer>\n                {children}\n            </PaddContainer> : children}\n        </ThemeProvider>\n    )\n}\n\nexport default Page\n","import React from \"react\"\nimport Page from '../../components/Layout/Page'\nimport { graphql } from \"gatsby\"\nimport * as styles from \"../../style/projects/agri.module.css\"\nimport { GatsbyImage } from \"gatsby-plugin-image\";\n\nfunction agri({ data }) {\n  var filteredData = {}\n\n  data.agri.edges.forEach(edge => {\n    filteredData[edge.node.name] = edge.node.childImageSharp.gatsbyImageData\n  })\n\n  return (\n    <Page darkNav addPadd title=\"Agri-Cane project\">\n      <div className={styles.container}>\n        <h2>AGRI-CANE</h2>\n        <h4 style={{ margin: \"0px 0px 50px\", textAlign: \"center\" }}>\n          Check it out on{\" \"}\n          <a\n            target=\"_blank\"\n            rel=\"noopener noreferrer\"\n            href=\"https://github.com/veeprayas/MAIN\"\n            style={{ color: \"blue\", textDecoration: \"underline\" }}\n          >\n            Github\n          </a>\n        </h4>\n        <div className={styles.float}>\n          <div>\n            <GatsbyImage image={filteredData.block} />\n            <p className={styles.figName}>Fig: Basic Block Diagram</p>\n          </div>\n          <div>\n            <div>\n              <h3 className=\"cinnabarH3\">Introduction</h3>\n              <p>\n                In today’s era, farmers face a lot of problems while growing\n                their crops. This could be due to lack of insight on the growth\n                requirements of the crop or due to environmental factors.<br />\n                We propose an autonomous system to montior the growth of plants from sowing till\n                cutting and monitor every aspect throughout.<br /> Additionally, we also propose to monitor the NPK (Nitrogen, Phosphorous, Potassium) and pH values of soil so farmers can better treat their crops.<br /> A block diagram outlining the system has been shown.\n              </p>\n\n              <h3 className=\"cinnabarH3\">POC Goals</h3>\n              <ul>\n                <li>\n                  Create a system for the detection of disease in plants and spray suitable insecticide/ medicine to counteract.\n                </li>\n                <li>\n                  Implement notification system to notify farmer if human intervention needed for survival of crop.\n                </li>\n              </ul>\n\n            </div>\n          </div>\n        </div>\n\n        <h3 className=\"cinnabarH3\">Progress</h3>\n        <ul>\n          <li>\n            Implemented a Deep Convolution Neural Network to classify between diseased plants and healthy ones across several classes of crops.\n            <ul>\n              <li>\n                Deep-Learning applied to computer vision was\n                implemented to monitor leaves of plants and indicate whether\n                it is infected with disease or not.\n                Diseases which can be detected using image processing techniques have been incorporated.\n              </li>\n            </ul>\n          </li>\n          <li>\n            Deployed the Model on a Flask Webserver to run inference on a WebApp.\n          </li>\n          <li>\n            Set up electronics to run inference as an IoT Device at periodic intervals.\n          </li>\n        </ul>\n\n        <h3 className=\"cinnabarH3\">Next Work</h3>\n        <ul>\n          <li>\n            Run the model on the Embedded System for Edge Inference.\n          </li>\n          <li>\n            Interface peripheral devices to Notify and Spray Medicine on crops.\n          </li>\n        </ul>\n\n        <h3 className=\"cinnabarH3\">The Software</h3>\n        <p>\n          There are three main steps involved in the Image Processing portion of\n          this project.\n        </p>\n        <ul>\n          <li>\n            Pick an existing state-of-art Deep Learning Model for our image\n            classification.\n          </li>\n          <li>\n            Train it on an extensive image dataset such as Imagenet so it can\n            learn to extract the different features from images.\n          </li>\n          <li>\n            Apply some magic from Transfer Learning to make it \"transfer\" its\n            learnt skills of feature extraction on our plants, and detect\n            the presence of any disease.\n          </li>\n        </ul>\n\n        <h4 className=\"cinnabarH3\">INCEPTION V3</h4>\n        <p>\n          Inception v3 is a widely-used image recognition model that has been\n          shown to attain greater than 78.1% accuracy on the ImageNet dataset.\n          The model is the culmination of many ideas developed by multiple\n          researchers over the years. It is based on the original\n          paper:\"Rethinking the Inception Architecture for Computer Vision\" by\n          Szegedy.\n          <br />\n          <br />\n          Inception V3 is an example of a Convolution Neural Network which has\n          two parts:\n        </p>\n        <ul style={{ listStyleType: \"disc\" }}>\n          <li>\n            A convolution tool that splits the various features of the image for\n            analysis\n          </li>\n          <li>\n            A fully connected layer that uses the output of the convolution\n            layer to predict the best description for the image.\n          </li>\n        </ul>\n        <br />\n        The model itself is made up of symmetric and asymmetric building blocks,\n        including convolutions, average pooling, max pooling dropouts, and fully\n        connected layers. Batch norm is used extensively throughout the model\n        and applied to activation inputs. Loss is computed via Softmax. A\n        high-level diagram of the model is shown below:{\" \"}\n        <div>\n          <GatsbyImage image={filteredData.inception} />\n          <p className={styles.figName}>Fig: Inception v3 model</p>\n        </div>\n        <p>\n          The different layers used in the Deep learning model and their\n          functions are highlighted below\n        </p>\n        <ul>\n          <li>\n            <p>\n              <b>Convolution Layer:</b>These layers employ different sets of\n              filters, typically hundreds-thousands and combines the results,\n              feeding the output into the next layer. This layer has \"filters\"\n              that automatically detects \"values\" for its filters and detects\n              objects in steps{\" \"}\n            </p>\n            <ul>\n              <li>Detect \"Edges\" from pixel intensities</li>\n              <li>use \"Edges\" to detect \"Shapes\"</li>\n              <li>\n                use \"Shapes\" to detect high-level features like facial\n                structures or parts of a leaf.\n              </li>\n            </ul>\n          </li>\n          <li>\n            <p>\n              <b>Activation Layer:</b>After each CONV layer in a CNN, we apply a\n              nonlinear activation function, such as ReLU, ELU etc. Activation\n              layers are not technically “layers” (due to the fact that no\n              parameters/weights are learned inside an activation layer) and are\n              sometimes omitted from network architecture diagrams as it’s\n              assumed that an activation immediately follows a convolution.\n            </p>\n          </li>\n          <li>\n            <p>\n              <b>Pooling Layer:</b>It is common to insert POOL layers in-between\n              consecutive convolution layers. The primary function of the POOL\n              layer is to progressively reduce the spatial size (i.e., width and\n              height) of the input volume. Doing this allows us to reduce the\n              amount of parameters and computation in the network – pooling also\n              helps us control overfitting. Max pooling is typically done in the\n              middle of the CNN architecture to reduce spatial size, whereas\n              average pooling is normally used as the final layer of the network\n              (e.x., GoogLeNet, SqueezeNet, ResNet) where we wish to avoid using\n              FC layers entirely.\n            </p>\n          </li>\n          <li>\n            <p>\n              <b>Fully-Connected Layer:</b>Neurons in FC layers are\n              fully-connected to all activations in the previous layer, as is\n              the standard for feedforward neural networks. FC layers are always\n              placed at the end of the network.\n            </p>\n          </li>\n          <li>\n            <p>\n              <b>Dropout Layer:</b>Dropout is actually a form of regularization\n              that aims to help prevent overfitting by increasing testing\n              accuracy, perhaps at the expense of training accuracy. For each\n              mini-batch in our training set, dropout layers, with probability\n              p, randomly disconnect inputs from the preceding layer to the next\n              layer in the network architecture. The reason we apply dropout is\n              to reduce overfitting by explicitly altering the network\n              architecture at training time. Randomly dropping connections\n              ensures that no single node in the network is responsible for\n              “activating” when presented with a given pattern. Instead, dropout\n              ensures there are multiple, redundant nodes that will activate\n              when presented with similar inputs – this in turn helps our model\n              to generalize.\n            </p>\n          </li>\n        </ul>\n        <p>\n          Before the model can be used to recognize images, it must be trained.\n          This is usually done via supervised learning using a large set of\n          labeled images. Although Inception v3 can be trained from many\n          different labeled image sets,&nbsp;ImageNet&nbsp;is a common dataset\n          of choice. ImageNet has over ten million URLs of labeled images. About\n          a million of the images also have bounding boxes specifying a more\n          precise location for the labeled objects. For this model, the ImageNet\n          dataset is composed of 1,331,167 images which are split into training\n          and evaluation datasets containing 1,281,167 and 50,000 images,\n          respectively. The training and evaluation datasets are kept separate\n          intentionally. Only images from the training dataset are used to train\n          the model and only images from the evaluation dataset are used to\n          evaluate model accuracy.\n        </p>\n        <h3 className=\"cinnabarH3\">Transfer Learning</h3>\n        <div>\n          <GatsbyImage image={filteredData.transfer} />\n          <p className={styles.figName}>Fig: Transfer Learning</p>\n        </div>\n        <p>\n          Transfer learning is the improvement of learning in a new task through\n          the transfer of knowledge from a related task that has already been\n          learned.\n          <br />\n          Transfer learning is a machine learning method where a model developed\n          for a task is reused as the starting point for a model on a second\n          task.\n          <br />\n          It is a popular approach in deep learning where pre-trained models are\n          used as the starting point on computer vision and natural language\n          processing tasks given the vast compute and time resources required to\n          develop neural network models on these problems and from the huge\n          jumps in skill that they provide on related problems.\n        </p>\n        <p>\n          It is common to perform transfer learning with predictive modeling\n          problems that use image data as input.\n          <br /> This may be a prediction task that takes photographs or video\n          data as input.\n          <br /> For these types of problems, it is common to use a deep\n          learning model pre-trained for a large and challenging image\n          classification task such as the ImageNet 1000-class photograph\n          classification competition.\n          <br /> The research organizations that develop models for this\n          competition and do well often release their final model under a\n          permissive license for reuse. These models can take days or weeks to\n          train on modern hardware.\n          <br />\n          <br /> These models can be downloaded and incorporated directly into\n          new models that expect image data as input. <br />\n          <br />\n          This approach is effective because the images were trained on a large\n          corpus of photographs and require the model to make predictions on a\n          relatively large number of classes, in turn, requiring that the model\n          efficiently learn to extract features from photographs in order to\n          perform well on the problem.\n        </p>\n        <h3 className=\"cinnabarH3\">Proposed Model</h3>\n        <div>\n          <GatsbyImage\n            image={filteredData.proposed}\n            style={{ maxWidth: \"500px\", margin: \"auto\" }} />\n          <p className={styles.figName}>Fig: Proposed Model</p>\n        </div>\n        <p>\n          <b>Step 1:</b> Take input as the image (crop-disease pair image).\n          <br />\n          <b>Step 2:</b>Pre-processing plant images.\n          <br />\n          <b>Step 3:</b> Train the model with leaf disease.\n          <br />\n          <b>Step 4:</b> CNN Validation stage where we can increase the\n          efficiency before make any test, which is sort of as the development\n          environment. <br />\n          <b>Step 5:</b> Test the model <br />\n          <b>Step 6:</b> A website will appear where user can identify whether\n          the leaf is diseased or healthy. The main aim is to design a system\n          which is efficient and which provide disease name. For that purpose we\n          use two phase: 1st is training phase and 2nd is testing phase.\n          <br />\n          <br />\n          <b>\n            In 1\n            <span style={{ verticalAlign: \"super\", fontSize: \"10px\" }}>st</span>{\" \"}\n            phase:\n          </b>{\" \"}\n          Image acquisition, Image Pre-processing and CNN based training. <br />\n          <b>\n            In 2\n            <span style={{ verticalAlign: \"super\", fontSize: \"10px\" }}>nd</span>{\" \"}\n            phase:\n          </b>{\" \"}\n          Image acquisition, Image Pre-processing, Classification and disease\n          identification and pesticides identification.\n          <br />\n          <br />\n          <b style={{ fontSize: \"16px\" }}>**NOTE**</b>Due to the{\" \"}\n          <b>COVID-19 outbreak</b>, we were unsuccessful in gathering sufficient\n          image data to train our classifier on yellow leaf syndrome or red dot\n          disease as most travel was prohibited. Therefore, for experimentation\n          purpose we have used <b>Plant Village datasets</b>. The data records\n          contain 54,000 images. The images span 14 crop species: Apple,\n          Blueberry, Cherry, Corn, Grape, Orange, Peach, Bell Pepper, Potato,\n          Raspberry, Soybean, Squash, Strawberry, and Tomato. It contains images\n          of{\" \"}\n          <b>\n            17 fungal diseases, 4 bacterial diseases, 2 mold (oomycete)\n            diseases, 2 viral disease, and 1 disease caused by a mite\n          </b>\n          . 12 crop species also have images of healthy leaves that are{\" \"}\n          <b>not visibly </b>affected by a disease.\n        </p>\n        <div>\n          <GatsbyImage\n            image={filteredData.snippet}\n            style={{ maxWidth: \"500px\", margin: \"auto\" }} />\n          <p className={styles.figName}>Fig: Snippet of Dataset</p>\n        </div>\n        <h3 className=\"cinnabarH3\">RESULTS</h3>\n        <p>\n          Here is the final webapp landing page where the farmer is expected to\n          upload the image of the suagarcane leaf to check if it is diseased or\n          not.\n          <br />\n          The uploaded image is sent to the back end where the image processing\n          techniques are used to determine the state of the crop.\n        </p>\n        <div>\n          <GatsbyImage image={filteredData.landing} />\n          <p className={styles.figName}>\n            Fig: Web Application Image Upload page\n          </p>\n        </div>\n        <p>\n          After training the Inception v3 model on the ImageNet Dataset and\n          applying transfer learning to classify our required dataset, we end up\n          with the following Model Classification Report.\n        </p>\n        <div>\n          <GatsbyImage image={filteredData.Report} style={{ maxWidth: \"500px\", margin: \"auto\" }} />\n          <p className={styles.figName}>Fig: Model Classification Report</p>\n        </div>\n        <p>\n          {\" \"}\n          The matrix below shows which class of crop/ disease the picture taken\n          resembles and has highest probability with respect to the picture\n          uploaded. In this case the position 1 is of highest probability and\n          hence resembles class one disease. The matrix position with the\n          highest probability represents the class of leaf (image uploaded by\n          the farmer). Hence, this is used to say whether that particular crop\n          is diseased or not.\n        </p>\n        <div className={styles.float}>\n          <div>\n            <GatsbyImage image={filteredData.table} />\n            <p className={styles.figName}>\n              Fig: classification table for probability matrix verification\n            </p>\n          </div>\n\n          <div>\n            <GatsbyImage image={filteredData.matrix} />\n            <p className={styles.figName}>\n              Fig: Probability Matrix obtained after image processing\n            </p>\n          </div>\n        </div>\n      </div>\n    </Page>\n  );\n}\n\nexport const query = graphql`{\n  agri: allFile(filter: {relativeDirectory: {eq: \"agri\"}}) {\n    edges {\n      node {\n        name\n        childImageSharp {\n          gatsbyImageData(layout: FULL_WIDTH)\n        }\n      }\n    }\n  }\n}\n`\n\nexport default agri\n","// extracted by mini-css-extract-plugin\nexport const container = \"agri-module--container--2gg9p\";\nexport const float = \"agri-module--float---6Nrc\";\nexport const figName = \"agri-module--figName--3oxbX\";"],"sourceRoot":""}